Cross-Marketplace Laptop & Review Intelligence Engine

This project builds an insights engine for specific business laptops sold on Lenovo and HP first-party stores, fulfilling the requirements of the â€œCross-Marketplace Laptop & Review Intelligenceâ€ assignment.
It leverages Retrieval-Augmented Generation (RAG) to combine canonical technical specifications from PDFs with mutable data (price, reviews, availability) scraped or manually entered from brand websites â€” enabling interactive analytics and a chatbot interface.

ğŸš© Problem Statement

Create a system that can:

Answer natural-language questions about laptop specifications.

Provide purchase recommendations with verifiable citations.

Offer analytical insights about four business laptops:

Lenovo ThinkPad E14 Gen 5 (â Intelâ )

Lenovo ThinkPad E14 Gen 5 (â AMDâ )

HP ProBook 450 G10

HP ProBook 440 G11

Sources:

PDF spec sheets â†’ immutable ground truth.

Brand product pages â†’ dynamic data (price, reviews, availability).

âœ¨ Features

Coherent Dataset: Combines static PDF specs with dynamic marketplace data.

RAG Chatbot: Answers questions using Google Gemini with source citations.

Laptop Recommender: Suggests models based on budget/spec constraints.

Interactive Exploration: Streamlit UI for filtering, browsing, and comparisons.

Reviews Intelligence: Charts for review trends and rating distributions.

Versioned REST API: Modular FastAPI backend with /docs auto-documentation.

Source Linking: Links to official PDF specification sheets.

ğŸ§© Tech Stack
Component	Technology
Backend	Python Â· FastAPI Â· Uvicorn
Frontend	Streamlit
LLM	Google Gemini API (gemini-1.5-flash)
Vector Search	FAISS (faiss-cpu)
Embeddings	Sentence Transformers (all-MiniLM-L6-v2)
Database	SQLite
Data Manipulation & Charts	Pandas Â· Plotly Express
API Calls	Requests
Environment	Conda
Config	python-dotenv
âš™ï¸ Architecture Overview

The system employs a Retrieval-Augmented Generation (RAG) pipeline combining:

Static data (technical specs â†’ PDF-derived JSON)

Dynamic data (market info â†’ SQLite)

LLM reasoning (Gemini API)

Vector retrieval (FAISS)

ğŸ“˜ Static Data Pipeline â€” Technical Specifications

Source:
4 official PDF spec sheets (Lenovo Ã— 2 Â· HP Ã— 2).

Processing & Chunking:
Text extracted and manually segmented into semantic sections (â€œProcessorâ€, â€œMemoryâ€, â€œPortsâ€, etc.) â†’ structured as JSON.

JSON Schema:

{
  "section_title": "Processor",
  "content": "Up to Intel Core i7...",
  "subfeatures": ["Intel Core i5", "Intel Core i7"],
  "source_model": "ThinkPad E14 Gen 5 (Intel)",
  "source_citations": [12, 13]
}


Embedding & Indexing:

Embeddings â†’ Sentence Transformer (all-MiniLM-L6-v2, 384 dims)

Stored in FAISS IndexFlatL2 (backend/laptops.index)

Metadata parallel JSON â†’ backend/laptops_metadata.json

Each vector â†” metadata record (content, sku, section_title, citations).

ğŸ“Š Dynamic Data Pipeline â€” Market Information

Source:
Manual / synthetic data from Lenovo + HP product pages (price, availability, reviews).

Storage: SQLite (backend/laptops_dynamic.db)

Schema Overview:

Table	Purpose
Laptop	Brand, model, availability, rating, currency
PriceHistory	Price points + dates + vendor
Review	Individual reviews (rating, text, date)
QuestionAnswer	User Q&A entries

All linked via sku â†” source_model.

ğŸ§  Backend API â€” FastAPI

Structure:

backend/app/
â”œâ”€â”€ config.py          # Env vars, API key loading
â”œâ”€â”€ main.py            # FastAPI app + endpoints
â”œâ”€â”€ models.py          # Pydantic response/request models
â”œâ”€â”€ rag_handler.py     # Core RAG logic
â””â”€â”€ utils.py           # FAISS, metadata, DB, Gemini helpers


RAG Flow:

Embed user query.

Search FAISS index â†’ relevant spec chunks.

Retrieve metadata + citations.

Identify related SKUs.

Query SQLite for dynamic data.

Compose prompt â†’ Gemini API (including static + dynamic context).

Return LLM response + citations.

Docs:
Auto-generated via FastAPI â†’ /docs

ğŸ–¥ï¸ Frontend UI â€” Streamlit

File: streamlit_app.py
Features:

Chat interface with session history (last 5 messages).

Fetches data via HTTP â†’ FastAPI endpoints (never touches DB directly).

Filter laptops by brand/rating/availability.

Interactive price & review charts (via Plotly Express).

ğŸ“ Project Structure
/laptop-agent
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ rag_handler.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”œâ”€â”€ .env              # API key (not committed)
â”‚   â”œâ”€â”€ .env.example      # Template
â”‚   â”œâ”€â”€ laptops.index
â”‚   â”œâ”€â”€ laptops_metadata.json
â”‚   â”œâ”€â”€ laptops_dynamic.db
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ data/                 # Source JSONs from PDFs
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_vector_index.ipynb / .py
â”‚   â””â”€â”€ setup_dynamic_db.ipynb  / .py
â”œâ”€â”€ streamlit_app.py
â”œâ”€â”€ schema_diagram.png
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

ğŸš€ Setup & Run Instructions
1ï¸âƒ£ Prerequisites

Python â‰¥ 3.9

Conda

Git

2ï¸âƒ£ Clone the Repository
git clone https://github.com/<your-github-username>/<your-repo-name>.git
cd <your-repo-name>

3ï¸âƒ£ Create & Activate Environment
conda create --name AgentInbox python=3.10 -y
conda activate AgentInbox

4ï¸âƒ£ Install Dependencies

Backend:

cd backend
pip install -r requirements.txt


Frontend:

cd ..
pip install streamlit pandas plotly requests

5ï¸âƒ£ Set Environment Variables
cd backend
cp .env.example .env
# then edit .env:
GOOGLE_API_KEY=your_actual_google_api_key_here

6ï¸âƒ£ Generate Data Artifacts

Dynamic Database:

python scripts/setup_dynamic_db.py
# or run: scripts/setup_dynamic_db.ipynb


FAISS Index:

python scripts/build_vector_index.py
# or run: scripts/build_vector_index.ipynb


Ensure PDF-derived JSON files exist in /data.

7ï¸âƒ£ Run Backend API
cd backend
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

8ï¸âƒ£ Run Frontend UI

Open a new terminal:

cd laptop-agent
conda activate AgentInbox
streamlit run streamlit_app.py


Then visit:
ğŸ‘‰ http://localhost:8501

âœ… Youâ€™re Ready!

FastAPI â†’ http://localhost:8000/docs

Streamlit â†’ http://localhost:8501
