{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ca8d485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import sqlite3 \n",
    "from contextlib import contextmanager \n",
    "import pandas as pd \n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd980c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index path: /Users/dilshantharushika/Desktop/laptop agent/backend/laptops.index\n",
      "Metadata path: /Users/dilshantharushika/Desktop/laptop agent/backend/laptops_metadata.json\n",
      "Dynamic DB path: /Users/dilshantharushika/Desktop/laptop agent/backend/laptops_dynamic.db\n",
      "Using Embedding Model: all-MiniLM-L6-v2\n",
      "Using LLM: gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BACKEND_DIR = '/Users/dilshantharushika/Desktop/laptop agent/backend' \n",
    "INDEX_PATH = '/Users/dilshantharushika/Desktop/laptop agent/backend/laptops.index' \n",
    "METADATA_PATH = '/Users/dilshantharushika/Desktop/laptop agent/backend/laptops_metadata.json' \n",
    "DB_PATH = '/Users/dilshantharushika/Desktop/laptop agent/backend/laptops_dynamic.db'\n",
    "\n",
    "EMBEDDING_MODEL_NAME = 'all-MiniLM-L6-v2' \n",
    "GEMINI_MODEL_NAME = 'gemini-2.5-flash' #\n",
    "\n",
    "print(f\"FAISS index path: {os.path.abspath(INDEX_PATH)}\")\n",
    "print(f\"Metadata path: {os.path.abspath(METADATA_PATH)}\")\n",
    "print(f\"Dynamic DB path: {os.path.abspath(DB_PATH)}\")\n",
    "print(f\"Using Embedding Model: {EMBEDDING_MODEL_NAME}\")\n",
    "print(f\"Using LLM: {GEMINI_MODEL_NAME}\")\n",
    "\n",
    "\n",
    "if not os.path.exists(INDEX_PATH): print(f\"WARNING: FAISS Index not found at {INDEX_PATH}\")\n",
    "if not os.path.exists(METADATA_PATH): print(f\"WARNING: Metadata file not found at {METADATA_PATH}\")\n",
    "if not os.path.exists(DB_PATH): print(f\"WARNING: SQLite DB not found at {DB_PATH}. Run setup_dynamic_db notebook/script.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47697950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading static RAG artifacts (FAISS, Metadata, Embedding Model)...\n",
      " RAG artifacts loaded successfully! \n",
      "Index contains 291 vectors.\n",
      "Metadata contains 291 entries.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Loading static RAG artifacts (FAISS, Metadata, Embedding Model)...\")\n",
    "embedding_model = None\n",
    "faiss_index = None\n",
    "metadata_store = None\n",
    "\n",
    "try:\n",
    "    if os.path.exists(INDEX_PATH) and os.path.exists(METADATA_PATH):\n",
    "        embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "        faiss_index = faiss.read_index(INDEX_PATH)\n",
    "        with open(METADATA_PATH, 'r', encoding='utf-8') as f:\n",
    "            metadata_store = json.load(f)\n",
    "        print(\" RAG artifacts loaded successfully! \")\n",
    "        print(f\"Index contains {faiss_index.ntotal} vectors.\")\n",
    "        print(f\"Metadata contains {len(metadata_store)} entries.\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Index or Metadata file missing.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading static RAG artifacts: {e}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7149aefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading .env file.\n",
      "Configuring Google Generative AI client...\n",
      "Google client configured successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Loading .env file.\")\n",
    "load_dotenv() \n",
    "\n",
    "print(\"Configuring Google Generative AI client...\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "llm_model = None \n",
    "\n",
    "if not google_api_key:\n",
    "    print(\"Error: GOOGLE_API_KEY not found in environment.\")\n",
    "    print(\"Please create a .env file in this directory with GOOGLE_API_KEY=your-key\")\n",
    "else:\n",
    "    try:\n",
    "        genai.configure(api_key=google_api_key)\n",
    "        llm_model = genai.GenerativeModel(GEMINI_MODEL_NAME)\n",
    "\n",
    "        print(\"Google client configured successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error configuring Google client (is API key valid/enabled?): {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afde5f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "@contextmanager\n",
    "def get_db_connection():\n",
    "    \"\"\"Provides a managed database connection to the dynamic DB.\"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        if not os.path.exists(DB_PATH):\n",
    "             raise FileNotFoundError(f\"Database file not found at {DB_PATH}. Run the setup_dynamic_db notebook/script first.\")\n",
    "        conn = sqlite3.connect(DB_PATH)\n",
    "        conn.row_factory = sqlite3.Row \n",
    "        yield conn\n",
    "    except Exception as e:\n",
    "        print(f\"Database connection error: {e}\")\n",
    "        yield None \n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "def get_dynamic_data_for_sku(sku):\n",
    "    \"\"\"Fetches latest price, rating, availability etc. for a given SKU from SQLite.\"\"\"\n",
    "    dynamic_info = {\"latest_price\": \"N/A\", \"avg_rating\": \"N/A\", \"availability\": \"N/A\", \"shipping_eta\": \"N/A\", \"vendor\": \"N/A\"}\n",
    "    try:\n",
    "        with get_db_connection() as conn:\n",
    "            if conn is None:\n",
    "                print(f\"Skipping dynamic data for {sku} due to connection error.\")\n",
    "                return dynamic_info \n",
    "            cursor = conn.cursor()\n",
    "\n",
    "           \n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT price, date, vendor_name, promo_badges\n",
    "                FROM PriceHistory\n",
    "                WHERE laptop_sku = ?\n",
    "                ORDER BY date DESC\n",
    "                LIMIT 1\n",
    "            \"\"\", (sku,))\n",
    "            latest_price_row = cursor.fetchone()\n",
    "\n",
    "          \n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT currency, average_rating, review_count, availability, shipping_eta\n",
    "                FROM Laptop\n",
    "                WHERE sku = ?\n",
    "            \"\"\", (sku,))\n",
    "            laptop_row = cursor.fetchone()\n",
    "\n",
    "         \n",
    "            if laptop_row:\n",
    "                 dynamic_info[\"avg_rating\"] = f\"{laptop_row['average_rating']:.1f}/5.0 ({laptop_row['review_count']} reviews)\"\n",
    "                 dynamic_info[\"availability\"] = laptop_row['availability']\n",
    "                 dynamic_info[\"shipping_eta\"] = laptop_row['shipping_eta']\n",
    "                 currency = laptop_row['currency']\n",
    "            else:\n",
    "                 print(f\"Warning: Laptop details not found in DB for SKU: {sku}\")\n",
    "                 currency = \"Unknown Currency\" \n",
    "\n",
    "            if latest_price_row:\n",
    "                dynamic_info[\"latest_price\"] = f\"{currency} {latest_price_row['price']:.2f}\"\n",
    "                if latest_price_row['promo_badges'] and latest_price_row['promo_badges'].lower() != \"none\":\n",
    "                     dynamic_info[\"latest_price\"] += f\" ({latest_price_row['promo_badges']})\"\n",
    "                dynamic_info[\"vendor\"] = latest_price_row['vendor_name'] if latest_price_row['vendor_name'] else \"N/A\"\n",
    "            else:\n",
    "                 print(f\"Warning: No price history found in DB for SKU: {sku}\")\n",
    "\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"SQLite error fetching dynamic data for SKU '{sku}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error fetching dynamic data for SKU '{sku}': {e}\")\n",
    "\n",
    "    return dynamic_info\n",
    "\n",
    "print(\"Database helper functions defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bde742a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined RAG function `query_rag_system_with_dynamic` defined.\n"
     ]
    }
   ],
   "source": [
    "def query_rag_system_with_dynamic(query, k=4):\n",
    "    \"\"\"\n",
    "    Performs RAG using FAISS (static specs) and SQLite (dynamic data) with Google Gemini.\n",
    "    \"\"\"\n",
    "\n",
    "    if not all([embedding_model, faiss_index, metadata_store, llm_model]):\n",
    "        print(\"Error: One or more components (embedding model, index, metadata, LLM) failed to load.\")\n",
    "        print(\"Please check previous cell outputs for errors (e.g., file paths, API keys).\")\n",
    "        return {\"answer\": \"Error: System components not loaded.\", \"context_summary\": {}}\n",
    "\n",
    "    print(f\"\\n Processing Query: '{query}' \")\n",
    "\n",
    "   \n",
    "    print(\"Step 1: Retrieving static specs from FAISS...\")\n",
    "    start_retrieve_static = time.time()\n",
    "    try:\n",
    "        query_vector = embedding_model.encode([query]).astype('float32')\n",
    "        distances, indices = faiss_index.search(query_vector, k)\n",
    "        retrieved_chunks = [metadata_store[i] for i in indices[0]]\n",
    "    except Exception as e:\n",
    "        print(f\"  Error during FAISS search: {e}\")\n",
    "        return {\"answer\": f\"Error during search: {e}\", \"context_summary\": {}}\n",
    "    end_retrieve_static = time.time()\n",
    "    print(f\"  > Done ({len(retrieved_chunks)} chunks) in {end_retrieve_static - start_retrieve_static:.3f} seconds.\")\n",
    "\n",
    "    \n",
    "    print(\"Step 1b: Retrieving dynamic data from SQLite...\")\n",
    "    start_retrieve_dynamic = time.time()\n",
    "    \n",
    "    mentioned_skus = sorted(list(set(chunk['sku'] for chunk in retrieved_chunks if chunk.get('sku'))))\n",
    "    print(f\"  Identified SKUs in static context: {mentioned_skus}\")\n",
    "\n",
    "    dynamic_context_dict = {} \n",
    "    if not mentioned_skus:\n",
    "        print(\"  > No specific laptop model identified in static context.\")\n",
    "    else:\n",
    "        for sku in mentioned_skus:\n",
    "             dynamic_context_dict[sku] = get_dynamic_data_for_sku(sku) \n",
    "    end_retrieve_dynamic = time.time()\n",
    "    print(f\"  > Done in {end_retrieve_dynamic - start_retrieve_dynamic:.3f} seconds.\")\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Step 2: Augmenting context for LLM...\")\n",
    "    \n",
    "    static_context_string = \"\\n--- STATIC SPECIFICATIONS CONTEXT ---\\n\"\n",
    "    if not retrieved_chunks:\n",
    "        static_context_string += \"No relevant specifications found.\\n\"\n",
    "    else:\n",
    "        for i, chunk in enumerate(retrieved_chunks):\n",
    "            static_context_string += f\"Context {i+1} (Source: {chunk.get('sku', 'Unknown')}, Section: {chunk.get('section_title', 'N/A')}):\\n\"\n",
    "            static_context_string += f\"  Content: {chunk.get('text', 'N/A')}\\n\"\n",
    "            if chunk.get('citations'):\n",
    "                static_context_string += f\"  Citations: {chunk['citations']}\\n\\n\"\n",
    "            else:\n",
    "                static_context_string += \"\\n\"\n",
    "\n",
    "\n",
    "    dynamic_context_string = \"\\n--- CURRENT DYNAMIC DATA ---\\n\"\n",
    "    if not dynamic_context_dict:\n",
    "         dynamic_context_string += \"No dynamic data retrieved for identified models.\\n\"\n",
    "    else:\n",
    "        for sku, data in dynamic_context_dict.items():\n",
    "             dynamic_context_string += f\"For '{sku}':\\n\"\n",
    "             dynamic_context_string += f\"  - Latest Price: {data.get('latest_price', 'N/A')}\\n\"\n",
    "             dynamic_context_string += f\"  - Availability: {data.get('availability', 'N/A')}\\n\"\n",
    "             # dynamic_context_string += f\"  - Shipping ETA: {data.get('shipping_eta', 'N/A')}\\n\" \n",
    "             dynamic_context_string += f\"  - Average Rating: {data.get('avg_rating', 'N/A')}\\n\\n\"\n",
    "\n",
    "\n",
    "    combined_context = static_context_string + dynamic_context_string\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert Q&A assistant and recommender for laptop specifications.\n",
    "    Your answers must be accurate and concise, directly based on the provided context ONLY (both static specs and dynamic data).\n",
    "    Do not use any outside knowledge or information not present in the context.\n",
    "    Prioritize dynamic data like price, availability, and rating if the query specifically asks for it or implies a purchase decision (e.g., \"recommend\", \"cheapest\", \"available\").\n",
    "    [cite_start]When you use information from the 'STATIC SPECIFICATIONS CONTEXT', you MUST cite the 'Citations' number provided (e.g., [cite: 123]). Do not make up citations. Cite specific citations when possible.\n",
    "    When you use information from 'CURRENT DYNAMIC DATA', clearly state it (e.g., \"The current price is...\", \"It is currently In Stock.\", \"The average rating is...\"). Do not add citations for dynamic data.\n",
    "\n",
    "    Here is the context retrieved from internal databases:\n",
    "    {combined_context}\n",
    "    --- END CONTEXT ---\n",
    "\n",
    "    Based *only* on the context provided above, please answer the following question or fulfill the recommendation request:\n",
    "    Question: {query}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    " \n",
    "    print(\"Step 3: Generating answer using Google Gemini...\")\n",
    "    llm_answer = \"Error: LLM generation failed.\" \n",
    "    start_generate = time.time()\n",
    "    try:\n",
    "        generation_config = genai.types.GenerationConfig(\n",
    "            temperature=0.0, \n",
    "            max_output_tokens=768\n",
    "        )\n",
    "       \n",
    "        response = llm_model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=generation_config,\n",
    "            \n",
    "        )\n",
    "\n",
    "   \n",
    "        if not response.parts:\n",
    "             if hasattr(response, 'prompt_feedback') and response.prompt_feedback.block_reason:\n",
    "                 llm_answer = f\"Error: Content generation blocked by safety settings. Reason: {response.prompt_feedback.block_reason}\"\n",
    "                 print(f\"  > Generation Blocked: {response.prompt_feedback.block_reason}\")\n",
    "             else:\n",
    "                 llm_answer = \"Error: LLM response was empty or blocked for an unknown reason.\"\n",
    "                 print(\"  > Generation Error: Empty or unknown block.\")\n",
    "        else:\n",
    "             llm_answer = response.text.strip()\n",
    "             end_generate = time.time()\n",
    "             print(f\"  > Done in {end_generate - start_generate:.3f} seconds.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        end_generate = time.time()\n",
    "        print(f\"  > Generation failed after {end_generate - start_generate:.3f} seconds.\")\n",
    "        print(f\"  Error during Google Gemini API call: {e}\")\n",
    "        llm_answer = f\"Error during LLM call: {e}\" \n",
    "\n",
    "    \n",
    "    print(\"\\n--- LLM Answer ---\")\n",
    "    print(llm_answer)\n",
    "\n",
    "   \n",
    "    return {\"answer\": llm_answer, \"context_summary\": {\"static_chunks_retrieved\": len(retrieved_chunks), \"dynamic_skus_queried\": mentioned_skus}}\n",
    "\n",
    "print(\"Combined RAG function `query_rag_system_with_dynamic` defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c2de26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing Query: 'What is the current price and availability of the ThinkPad E14 Gen 5 Intel?' \n",
      "Step 1: Retrieving static specs from FAISS...\n",
      "  > Done (4 chunks) in 0.141 seconds.\n",
      "Step 1b: Retrieving dynamic data from SQLite...\n",
      "  Identified SKUs in static context: ['HP ProBook 440 14 inch G11 Notebook PC', 'Lenovo ThinkPad E14 Gen 5 (AMD)', 'ThinkPad E14 Gen 5 (Intel)']\n",
      "  > Done in 0.002 seconds.\n",
      "Step 2: Augmenting context for LLM...\n",
      "Step 3: Generating answer using Google Gemini...\n",
      "  > Done in 8.520 seconds.\n",
      "\n",
      "--- LLM Answer ---\n",
      "The current price for the ThinkPad E14 Gen 5 (Intel) is LKR 369896.71, and it is currently In Stock.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results1 = query_rag_system_with_dynamic(\"What is the current price and availability of the ThinkPad E14 Gen 5 Intel?\")\n",
    "print(\"-\" * 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f4697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgentInbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
